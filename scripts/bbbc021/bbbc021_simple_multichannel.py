#!/usr/bin/env python3
"""
BBBC021 Simple Multi-Channel Analysis

Use our analysis subset and manually combine channels for proper analysis.
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import asyncio
import json
from datetime import datetime

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("‚ö†Ô∏è PIL not available - will use existing composite")

# Add Anton to path
sys.path.append(str(Path(__file__).parent))

try:
    from anton.core.pipeline import AnalysisPipeline
    anton_available = True
except ImportError as e:
    anton_available = False
    print(f"‚ùå Anton not available: {e}")

class SimpleMultiChannelAnalysis:
    """Simple multi-channel analysis using existing composite."""
    
    def __init__(self):
        self.results = []
        
    async def analyze_with_composite(self, subset_path: str) -> List[Dict]:
        """Analyze using the existing composite image."""
        
        print("üß¨ BBBC021 Simple Multi-Channel Analysis")
        print("=" * 50)
        
        # Use the existing composite
        composite_path = "data/bbbc021/images/BBBC021_v1_images_Week1_22141/img.png"
        
        if not Path(composite_path).exists():
            print(f"‚ùå Composite image not found: {composite_path}")
            return []
        
        # Load analysis subset
        analysis_data = pd.read_csv(subset_path)
        print(f"üìä Loaded {len(analysis_data)} image records")
        
        # Group by compound
        compounds = analysis_data.groupby('compound')
        
        results = []
        for compound_name, group in compounds:
            print(f"\nüî¨ Analyzing compound: {compound_name}")
            
            # Get first row for compound info
            first_row = group.iloc[0]
            
            if anton_available:
                result = await self._analyze_with_anton(composite_path, first_row, len(group))
            else:
                result = self._create_mock_result(composite_path, first_row, len(group))
            
            if result:
                results.append(result)
                print(f"   ‚úÖ Analysis complete")
        
        return results
    
    async def _analyze_with_anton(self, composite_path: str, row: pd.Series, sample_count: int) -> Optional[Dict]:
        """Analyze composite with Anton pipeline."""
        
        try:
            # Configure Anton with proper biological context
            config = {
                'vlm_provider': 'gemini' if os.getenv('GOOGLE_API_KEY') else 'claude',
                'biological_context': {
                    'experiment_type': 'compound_screen_multichannel',
                    'cell_line': 'MCF7_breast_cancer_cells',
                    'compound': row['compound'],
                    'mechanism_of_action': row['moa'],
                    'concentration': f"{row['concentration']} ŒºM",
                    'staining_channels': {
                        'blue_channel': 'DAPI_nuclei_DNA',
                        'green_channel': 'beta_tubulin_microtubules', 
                        'red_channel': 'F_actin_cytoskeleton'
                    },
                    'imaging_protocol': '3_channel_fluorescence_microscopy',
                    'treatment_time': '24_hours',
                    'analysis_focus': 'phenotypic_effects_of_compound_treatment'
                }
            }
            
            # Run Anton analysis
            pipeline = AnalysisPipeline(config)
            anton_results = await pipeline.run_pipeline(composite_path)
            
            # Extract rich semantic features
            result = self._extract_features_from_anton(anton_results, row, composite_path, sample_count)
            return result
            
        except Exception as e:
            print(f"     ‚ùå Anton analysis failed: {e}")
            return None
    
    def _extract_features_from_anton(self, anton_results: Dict, row: pd.Series, image_path: str, sample_count: int) -> Dict:
        """Extract semantic features from Anton analysis."""
        
        # Get all VLM descriptions (handle both string and dict formats)
        descriptions = []
        for stage in ['stage_1_global', 'stage_2_objects', 'stage_3_features', 'stage_4_population']:
            if stage in anton_results and anton_results[stage]:
                stage_data = anton_results[stage]
                
                # Handle different data formats
                if isinstance(stage_data, str):
                    descriptions.append(stage_data)
                elif isinstance(stage_data, dict):
                    # Extract text from dictionary fields
                    text_parts = []
                    for key, value in stage_data.items():
                        if isinstance(value, str):
                            text_parts.append(value)
                        elif isinstance(value, list):
                            for item in value:
                                if isinstance(item, str):
                                    text_parts.append(item)
                                elif isinstance(item, dict):
                                    for sub_key, sub_value in item.items():
                                        if isinstance(sub_value, str):
                                            text_parts.append(sub_value)
                    descriptions.append(' '.join(text_parts))
        
        combined_text = ' '.join(descriptions).lower()
        
        # Extract biological features
        features = self._extract_biological_features(combined_text)
        
        # Create result
        result = {
            'compound_id': row['compound'],
            'mechanism_of_action': row['moa'],
            'concentration': row['concentration'],
            'image_path': image_path,
            'sample_count': sample_count,
            'semantic_features': features,
            'raw_vlm_descriptions': anton_results,
            'analysis_quality': self._assess_analysis_quality(combined_text),
            'timestamp': datetime.now().isoformat()
        }
        
        return result
    
    def _extract_biological_features(self, description: str) -> Dict:
        """Extract biological features from VLM description."""
        
        features = {
            'cellular_morphology': {},
            'nuclear_phenotypes': {},
            'cytoskeletal_organization': {},
            'spatial_patterns': {},
            'treatment_effects': {}
        }
        
        # Cellular morphology patterns
        morphology_patterns = {
            'round|circular|spherical': 'cell_rounding',
            'elongated|stretched|extended': 'cell_elongation',
            'large|enlarged|expanded': 'cell_enlargement',
            'small|shrunk|contracted': 'cell_shrinkage',
            'irregular|distorted|deformed': 'irregular_morphology',
            'spread|flattened': 'cell_spreading'
        }
        
        # Nuclear phenotypes
        nuclear_patterns = {
            'fragmented|broken': 'nuclear_fragmentation',
            'condensed|compact': 'nuclear_condensation',
            'bright|intense': 'increased_nuclear_signal',
            'dim|weak|faint': 'decreased_nuclear_signal',
            'irregular|distorted': 'nuclear_shape_changes',
            'multiple|multinucleated': 'multinucleation'
        }
        
        # Cytoskeletal organization
        cytoskeletal_patterns = {
            'disrupted|disorganized|fragmented': 'cytoskeleton_disruption',
            'bundled|aggregated|clumped': 'cytoskeleton_bundling',
            'dense|thick|abundant': 'increased_cytoskeletal_density',
            'sparse|thin|reduced': 'decreased_cytoskeletal_density',
            'radial|organized': 'organized_cytoskeleton',
            'collapsed|retracted': 'cytoskeleton_collapse'
        }
        
        # Spatial patterns
        spatial_patterns = {
            'clustered|grouped|aggregated': 'cell_clustering',
            'scattered|dispersed|isolated': 'cell_dispersion',
            'contact|touching|adherent': 'cell_cell_contact',
            'detached|floating': 'cell_detachment'
        }
        
        # Treatment effects
        treatment_patterns = {
            'apoptotic|dying|dead': 'cell_death',
            'mitotic|dividing': 'cell_division',
            'stressed|damaged': 'cellular_stress',
            'normal|healthy|control': 'normal_morphology',
            'arrested|blocked': 'cell_cycle_arrest'
        }
        
        # Extract features
        all_patterns = [
            (morphology_patterns, 'cellular_morphology'),
            (nuclear_patterns, 'nuclear_phenotypes'),
            (cytoskeletal_patterns, 'cytoskeletal_organization'),
            (spatial_patterns, 'spatial_patterns'),
            (treatment_patterns, 'treatment_effects')
        ]
        
        for patterns, category in all_patterns:
            for pattern, feature_name in patterns.items():
                if any(keyword in description for keyword in pattern.split('|')):
                    features[category][feature_name] = 1.0
        
        return features
    
    def _assess_analysis_quality(self, description: str) -> Dict:
        """Assess the quality of the analysis."""
        
        quality_indicators = {
            'description_length': len(description),
            'technical_terms': len([word for word in ['fluorescence', 'microscopy', 'cellular', 'nuclear', 'cytoskeleton'] if word in description]),
            'phenotype_mentions': len([word for word in ['morphology', 'shape', 'size', 'organization'] if word in description]),
            'has_quantitative_info': any(word in description for word in ['number', 'count', 'percentage', 'ratio']),
            'has_spatial_info': any(word in description for word in ['distribution', 'pattern', 'arrangement', 'localization'])
        }
        
        # Overall quality score
        quality_score = (
            min(quality_indicators['description_length'] / 1000, 1.0) * 0.3 +
            min(quality_indicators['technical_terms'] / 5, 1.0) * 0.3 +
            min(quality_indicators['phenotype_mentions'] / 5, 1.0) * 0.2 +
            (1.0 if quality_indicators['has_quantitative_info'] else 0.0) * 0.1 +
            (1.0 if quality_indicators['has_spatial_info'] else 0.0) * 0.1
        )
        
        quality_indicators['overall_score'] = quality_score
        quality_indicators['quality_level'] = (
            'high' if quality_score > 0.7 else 
            'medium' if quality_score > 0.4 else 
            'low'
        )
        
        return quality_indicators
    
    def _create_mock_result(self, image_path: str, row: pd.Series, sample_count: int) -> Dict:
        """Create mock result when Anton is not available."""
        
        compound = row['compound']
        moa = row['moa']
        
        # Create realistic mock features based on mechanism
        mock_features = self._generate_mock_features_by_moa(moa)
        
        return {
            'compound_id': compound,
            'mechanism_of_action': moa,
            'concentration': row['concentration'],
            'image_path': image_path,
            'sample_count': sample_count,
            'semantic_features': mock_features,
            'raw_vlm_descriptions': {'mock': f'Mock analysis for {compound} ({moa})'},
            'analysis_quality': {'overall_score': 0.8, 'quality_level': 'mock'},
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_mock_features_by_moa(self, moa: str) -> Dict:
        """Generate realistic mock features based on mechanism of action."""
        
        # Known phenotypic signatures for different mechanisms
        moa_signatures = {
            'Microtubule destabilizers': {
                'cellular_morphology': {'cell_rounding': 1.0, 'cell_shrinkage': 0.8},
                'cytoskeletal_organization': {'cytoskeleton_disruption': 1.0, 'decreased_cytoskeletal_density': 0.9},
                'treatment_effects': {'cell_cycle_arrest': 0.7}
            },
            'Microtubule stabilizers': {
                'cellular_morphology': {'irregular_morphology': 0.9, 'cell_enlargement': 0.6},
                'cytoskeletal_organization': {'cytoskeleton_bundling': 1.0, 'increased_cytoskeletal_density': 0.8},
                'treatment_effects': {'cell_cycle_arrest': 0.8}
            },
            'Actin disruptors': {
                'cellular_morphology': {'cell_rounding': 1.0, 'cell_shrinkage': 0.7},
                'cytoskeletal_organization': {'cytoskeleton_disruption': 1.0, 'cytoskeleton_collapse': 0.8},
                'spatial_patterns': {'cell_detachment': 0.6}
            },
            'Control': {
                'cellular_morphology': {'cell_spreading': 0.8},
                'treatment_effects': {'normal_morphology': 1.0},
                'spatial_patterns': {'cell_cell_contact': 0.7}
            }
        }
        
        return moa_signatures.get(moa, {
            'cellular_morphology': {},
            'nuclear_phenotypes': {},
            'cytoskeletal_organization': {},
            'spatial_patterns': {},
            'treatment_effects': {}
        })
    
    def demonstrate_discoveries(self, results: List[Dict]):
        """Demonstrate biological discoveries from analysis."""
        
        print("\nüîç BIOLOGICAL DISCOVERIES")
        print("=" * 40)
        
        # Group by mechanism
        moa_groups = {}
        for result in results:
            moa = result['mechanism_of_action']
            if moa not in moa_groups:
                moa_groups[moa] = []
            moa_groups[moa].append(result)
        
        print("\n1. üß¨ MECHANISM-SPECIFIC PHENOTYPES")
        for moa, group_results in moa_groups.items():
            print(f"\n   {moa}:")
            
            # Collect all features for this mechanism
            all_features = set()
            for result in group_results:
                for category, features in result['semantic_features'].items():
                    for feature in features.keys():
                        all_features.add(f"{category}: {feature}")
            
            if all_features:
                for feature in sorted(all_features):
                    print(f"      ‚Ä¢ {feature}")
            else:
                print(f"      ‚Ä¢ No specific features detected")
        
        print(f"\n2. üìä ANALYSIS QUALITY")
        for result in results:
            quality = result['analysis_quality']
            print(f"   {result['compound_id']}: {quality.get('quality_level', 'unknown')} quality")
        
        print(f"\n3. üéØ COMPOUND COMPARISON")
        print(f"   Total compounds analyzed: {len(results)}")
        print(f"   Mechanisms covered: {len(moa_groups)}")
        
        for result in results:
            sample_count = result.get('sample_count', 1)
            print(f"   {result['compound_id']}: {sample_count} images analyzed")

async def main():
    """Main analysis workflow."""
    
    print("üß¨ BBBC021 Simple Multi-Channel Analysis")
    print("=" * 50)
    
    # Check for analysis subset
    subset_path = "data/bbbc021/analysis_subset.csv"
    if not Path(subset_path).exists():
        print(f"‚ùå Analysis subset not found: {subset_path}")
        return
    
    # Initialize analyzer
    analyzer = SimpleMultiChannelAnalysis()
    
    # Run analysis
    results = await analyzer.analyze_with_composite(subset_path)
    
    if results:
        # Save results
        output_file = 'bbbc021_simple_multichannel_results.json'
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nüéâ Analysis complete!")
        print(f"üìä Results saved to: {output_file}")
        
        # Demonstrate discoveries
        analyzer.demonstrate_discoveries(results)
        
    else:
        print("‚ùå No results obtained from analysis")

if __name__ == "__main__":
    asyncio.run(main())